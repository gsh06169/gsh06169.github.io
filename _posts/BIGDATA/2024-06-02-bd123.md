---
title: "[BIGDATA] 1-1 [배경] 빅데이터의 정착"

categories: 
  - BIGDATA
tags:
  - [bigdata, 공부]

toc: true
toc_sticky: true
---

# 빅데이터의 기초 지식_1


## [배경] 빅데이터의 정착

### 분산 시스템에 의한 데이터 처리의 고속화 - 빅데이터의 취급하기 어려운 점을 극복한 두 가지 대표 기술

빅데이터의 취급이 어려운 이유는 크게 두 가지다. <br> 하나는 '데이터의 분석 방법을 모른다'는 점이고, 또 하나의 이유는 '데이터 처리에 수고와 시간이 걸린다'는 점이다. <br> 데이터가 있어도 그 가치를 창조하지 못한다면 의미가 없고, 지식이 있어도 시간을 많이 소비한다면 할 수 있는 것은 한정된다. <br> 이 두가지를 갖추고 나서야 비로소 가치 있는 정보를 얻을 수 있다.

가능한 한 적은 노력으로 원하는 정보를 얻을 수 있도록 지금 어떠한 기술이 사용되는지 차례대로 살펴보겠다.

#### 빅데이터 기술의 요구 (Hadoop과 NoSQL의 대두)

빅데이터의 기술로 가장 먼저 예로 들 수 있는 것이 'Hadoop'과 'NoSQL'이다.

인터넷 보급으로 세계 곳곳으로부터 액세스 되는 시스템이 증가함에 따라 전통적인 관계형 데이터베이스(RDB)로는 취급할 수 없을 만큼 대량의 데이터가 점차 쌓이게 되었다. <br> 그렇게 축적된 데이터를 처리하려면 기존과는 다른 구조가 필요했다. <br> Hadoop과 NoSQL은 각각 다른 요구를 충족하기 위해 태어났다.

- **Hadoop** (다수의 컴퓨터에서 대량의 데이터 처리)

Hadoop은 '다수의 컴퓨터에서 대량의 데이터를 처리하기'위한 시스템이다. <br> 예를 들어, 전 세계의 웹페이지를 모아서 검색 엔진을 만들려면 방대한 데이터를 저장해둘 스토리지와 데이터를 순차적으로 처리할 수 있는 구조가 필요하다. <br> 그러기 위해서는 수백 대, 수천 대 단위의 컴퓨터가 이용되어야 하며, 그것을 관리하는 것이 Hadoop이라는 프레임워크다.


Hadoop은 원래 구글에서 개발된 분산 처리 프레임워크인 'MapReduce'를 참고하여 제작되었다. <br> 초기 Hadoop에서 MapReduce를 동작시키려면 데이터 처리의 내용을 기술하기 위해 자바 언어로 프로그래밍을 해야 했다.


그래서 SQL과 같은 쿼리 언어를 Hadoop에서 실행하기 위한 소프트웨어로 'Hive(하이브)'가 개발되어 2009년에 출시되었다. <br> Hive의 도입에 의해 프로그래밍 없이 데이터를 집계할 수 있게 함으로써 많은 사람이 Hadoop을 이용한 분산 시스템의 혜택을 받을 수 있게 되었고, 그로 인해 점차 사용자를 확대할 수 있었다.

시기|이벤트
---|---
2004년 12월|구글에서 MapReduce 논문이 발표됨
2007년 9월|Hadoop의 최조 버전(0.14.1)이 배포되어 전 세계적으로 이용되기 시작함
2009년 5월|Hive의 최초 버전(0.3.0)이 배포됨
2011년 12월|Hadoop 1.0.0 배포


- **NoSQL 데이터베이스** (빈번한 읽기/쓰기 및 분산 처리가 강점)

NoSQL은 전통적인 RDB의 제약을 제거하는 것을 목표로 한 데이터베이스의 총칭이다. <br> NoSQL 데이터베이스에는 다양한 종류가 있다. <br> 다수의 키와 값을 관련지어 저장하는 '키 밸류 스토어(key-value store/KVS)', JSON과 같은 복잡한 데이터 구조를 저장하는 '도큐멘트 스토어(document store)', 여러 키를 사용하여 높은 확장성을 제공하는 '와이드 칼럼 스토어(wide-column store)' 등이 대표적이다.


NoSQL 데이터베이스 제품은 RDB보다 고속의 읽기, 쓰기가 가능하고 분산 처리에 뛰어나다는 특징을 갖추고 있다. <br> 모여진 데이터를 나중에 집계하는 것이 목적인 Hadoop과는 다르게 NoSQL은 애플리케이션에서 온라인으로 접속하는 데이터베이스다.

시기|이벤트|제품의 종류
---|---|---
2009년 8월|MongoDB 1.0 배포|도큐먼트 스토어
2010년 7월|CouchDB 1.0 배포|도큐먼트 스토어
2011년 9월|Riak 1.0 배포|키밸류 스토어
2011년 10월|Cassandra 1.0 배포|와이드 칼럼 스토어
2011년 12월|Redis 1.0 배포|키밸류 스토어


- **Hadoop과 NoSQL 데이터베이스의 조합** (현실적인 비용으로 대규모 데이터 처리 실현)

이 둘을 조합함으로써 'NoSQL 데이터베이스에 기록하고 Hadoop으로 분산 처리하기'라는 흐름이 2011년 말까지 정착하게 되었고, 2012년부터는 일반에 널리 퍼지게 되었다.



### 분산 시스템의 비즈니스 이용 개척 - 데이터 웨어하우스와의 공존


일부 기업에서는 이전부터 데이터 분석을 기반으로 하는 '엔터프라이즈 데이터 웨어하우스(enterprise data warehouse/EDW, 또는 데이투 웨어하우스/DWH)'를 도입했다.

분산 시스템의 발전에 딸, 기존이라면 데이터 웨어하우스 제품이 사용되는 경우에도 Hadoop을 사용하는 경우가 증가했다. <br> 다수의 데이터 분석 도구가 Hadoop에 대한 대응을 표명하여 대량의 데이터를 보존 및 집계하기 위해 Hadoop과 Hive를 사용하게 되었다. <br> 그 결과 Hadoop의 도입을 기술적으로 지원하는 비즈니스가 성립하게 되었고, 그때 사용하게 된 키워드가 바로 '빅데이터'다.

전통적인 데이터 웨어하우스에서도 대량의 데이터를 처리할 수 있으며, 오히려 여러 방면에서 Hadoop보다도 우수하지만 단점도 있다. <br> 일부 데이터 웨어하우스 제품은 안정적인 성능을 실현하기 위해 하드웨어와 소프트웨어가 통홥된 통합 장비(appliance)로 제공되었다. <br> 데이터 용량을 늘리려면 하드웨어를 교체해야 하는 등 나중에 확장하기가 쉽지 않았다. <br> 따라서, 가속도적으로 늘어나는 데이터의 처리는 Hadoop에 맡기고, 비교적 작은 데이터 또는 중요한 데이터만을 데이터 웨어하우스에 넣는 식으로 사용을 구분하게 되었다.

예를 드렁, 야간 배치 등 심야에 대량으로 발생하는 데이터 처리에 Hadoop을 사용하고 있는데, 야간 배치에서는 매일 거래되는 데이터 등을 심야에 집계하여 다음 날 아침까지 보고서에 정리한다. <br> 데이터양이 증가하면 배치 처리 또한 시간이 걸려 업무에 지장이 생기기 때문에 확장성이 뛰어난 Hadoop에 데이터 처리를 맡김으로써 데이터 웨어하우스의 부하를 줄이고 있다.

### 직접 할 수 있는 데이터 분석 폭 확대 - 클라우드 서비스와 데이터 디스커버리로 가속하는 빅데이터의 활용

'여러 컴퓨터에 분산 처리한다'라는 점이 빅데이터의 특징이지만 이를 위한 하드웨어를 준비하고 관리하는 일은 간단하지 않다. <br> 클라우드 시대인 요즘은 시간 단위로 필요한 자원을 확보할 수 있어서 방법만 알면 언제든지 이용할 수 있는 환경이 마련되었다.

시기|이벤트|서비스의 특징
---|---|---
2009년 4월|Amazon Elastic MapReduce 발표|클라우드를 위한 Hadoop
2010년 5월|구글 BigQuery 발표|데이터 웨어하우스
2012년 10월|Azure HdInsight 발표|클라우드를 위한 Hadoop
2012년 11월|Amazon Redshift 발표|데이터 웨어하우스

2012년 말에 'Amazon Redshift(아마존 레드시프트)'가 발표된 이후로 데이터 웨어하우스를 클라우드 상에서 작성하는 것은 그다지 드문 일이 아니었다. <br> 이전의 데이터 웨어하우스는 대기업의 IT 부서가 상당한 노력을 들여 구축해야 하는 매우 한정된 것이었지만, 이제는 더욱 작은 프로젝트 단위에서도 데이터 웨어하우스를 구축하여 자체적으로 데이터 분석 기반을 마련하는 경우가 일반적인 상황이 되었다.

**데이터 디스커버리의 기초지식** (셀프서비스용 BI 도구)

데이터 디스커버리(data discovery)란 '대화형으로 데이터를 시각화하여 가치 있는 정보를 찾으려고 하는 프로세스'를 가리키며, 2012년경부터 사용된 용어다.


데이터 디스커버리는 '셀프서비스용 BI도구'로 불린다. <br> 'BI 도구(business intelligence tool)'는 예전부터 데이터 웨어하우스와 조합되어 사용된 경영자용 시각화 시스템으로, 대기업의 IT 부서에 의해 도입되는 대규모의 도구다. <br> 셀프서비스용 BI 도구는 이것을 개인도 도입할 수 있을 정도로 단순화한 것이다.


2013년 이후에도 빅데이터 기술은 더 높은 '효율'과 '편리성'을 실현하기 위해 계속해서 개발되고 있다. <br> 'Apache Spark(아파치 스파크)'와 같은 새로운 분산 시스템용 프레임워크가 보급됨으로써 MapReduce보다도 효율적으로 데이터 처리를 할 수 있게 되었다. <br> 배치 처리뿐만 아니라 실시간 데이터 처리를 위한 시스템도 다수 만들어지고 있다.

