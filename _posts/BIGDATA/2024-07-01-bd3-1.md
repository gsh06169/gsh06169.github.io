---
title: "[BIGDATA] 3-1 대규모 분산 처리의 프레임워크"

categories: 
  - BIGDATA
tags:
  - [bigdata, 공부]

toc: true
toc_sticky: true
---

# 빅데이터의 분산 처리

## 대규모 분산 처리의 프레임워크

다수의 컴퓨터에 데이터 처리를 분산하기 위해서는 그 실행을 관리하기 위한 프레임워크가 필요하다.


### 구조화 데이터와 비구조화 데이터

SQL로 데이터를 집계하는 경우, 먼저 테이블의 칼럼 명과 데이터형, 테이블 간의 관계 등을 '스키마(schema)'로 정한다. <br> 스키마가 명확하게 정의된 데이터를 '구조화된 데이터(structured data)'라고 한다. <br> 기존의 데이터 웨어하우스에서는 데이터를 항상 구조화된 데이터로 축적하는 것이 일반적이었다.

한편, 빅데이터는 자연 언어로 작성된 텍스트 데이터와 이미지, 동영상 등의 미디어 데이터도 포함된다. <br> 이러한 스키마가 없는 데이터는 '비구조화 데이터(unstructed data)'라고 하고, 이 상태로는 SQL로 제대로 집계할 수 없다.

비구조화 데이터를 분산 스토리지 등에 저장하고 그것을 분산 시스템에서 처리하는 것이 데이터 레이크의 개념이다. <br> 데이터를 가공하는 과정에서 스키마를 정의하고, 구조화된 데이터로 변환함으로써 다른 데이터와 마찬가지로 분석할 수 있다.


**스키마리스 데이터** (기본 서식은 있지만, 스키마가 정의 안 됨)

CSV, JSON, XML 등의 데이터는 서식은 정해져 있지만, 칼럼 수나 데이터형은 명확하지 않아 '스키마리스 데이터(schemaless data)'라고 불린다. <br> 몇몇 NoSQL 데이터베이스는 스키마리스 데이터에 대응하고 있으며, 데이터 레이크에서는 대량으로 축적된 스키마리스 데이터를 효율적으로 처리하도록 하는 요구도 종종 있다.


새로운 데이터를 다움로드할 때마다 스키마를 정하는 것은 시간과 비용이 소요되기 때문에 JSON은 JSON 그대로 저장하고 거기서 데이터 분석에 필요한 필드만 추출하는 편이 간단하다. <br> 원래의 데이터만 그대로 보존되어 있으면, 처음부터 모든 필드를 꺼내지 않고도 나중에 얼마든지 추가 정보를 꺼낼 수 있다.



**데이터 구조화의 파이프라인** (테이블 형식으로 열 지향 스토리지에 장기 보존)

분산 스토리지에 수집된 명확한 스키마를 갖지 않는 데이터는 그냥 그대로는 SQL로 집계할 수 없다. <br> 따라서, 먼저 필요한 것은 스키마를 명확하게 한 테이블 형식의 '구조화 데이터'로 변환하는 것이다.


일반적으로 구조화 데이터는 데이터의 압축률을 높이기 위해 열 지향 스토리지로 저장한다.

구조화 데이터 중 시간에 따라 증가하는 데이터를 팩트 테이블, 그에 따른 부속 데이터를 디멘전 테이블로 취급한다.



**열 지향 스토리지의 작성** (분산 스토리지 상에 작성해 효율적으로 데이터를 집계)

MPP 데이터베이스의 경우, 제품에 따라 스토리지의 형식이 고정되어 있어 사용자가 그 상세를 몰라도 괜찮지만, Hadoop에서는 사용자가 직접 열 지향 스토리지의 형식을 선택하고, 자신이 좋아하는 쿼리 엔진에서 그것을 집계할 수 있다.

Hadoop에서 사용할 수 있는 열 지향 스토리지에는 몇 가지 종류가 있으며, 각각 특징이 다르다. <br>'Apache ORC'는 구조화 데이터를 위한 열 지향 스토리지로 처음에 스키마를 정한 후 데이터를 저장한다. <br> 한편 'Apache Parquet'은 스키마리스에 가까운 데이터 구조로 되어 있어 JSON 같은 뒤얽힌 데이터도 그대로 저장할 수 있다. 

비구조화 데이터를 읽어 들여 열 지향 스토리지로 변환하는 과정에서는 데이터의 가공 및 압축을 위해 많은 컴퓨터 리소스가 소비된다. <br> 그래서 사용되는 것이 Hadoop과 Spark 등의 분산 처리 프레임워크다.



### Hadoop - 분산 데이터 처리의 공통 플랫폼

Hadoop은 단일 소프트웨어가 아니라 분산 시스템을 구성하는 다수의 소프트웨어로 이루어진 집합체다. <br> 2013년 배보된 Hadoop2부터 YARN이라고 불리는 새로운 리소스 관리자 상에서 복수의 분산 애플리케이션이 동작하는 구성으로 되어, 대규모 분산시스템을 구축하기 위한 공통 플랫폼의 역할을 담당하고 있다.

시기|이벤트
---|---
2003년|Nutch 프로젝트 발족
2004년|Google MapReduce 논문
2006년|Apache Hadoop 프로젝트 발족
2011년|Apache Hadoop 1.0.0 배포
2013년|Apache Hadoop 2.2.0 배포(YARN 대응)
2014년|Apache Spark 1.0.0 배포
2016년|Apache Flink 1.0.0 배포
2016년|Apache Mesos 1.0.0 배포

![IMG_8339](https://github.com/gsh06169/gsh06169/assets/150469460/a9e80ccd-cee1-4f80-ae74-6dae64b7996e)



**분산 시스템의 구성 요소** (HDFS, YARN, MapReduce)

Hadoop의 기본 구성 요소는 '분산 파일 시스템(distributed file system)'인 'HDFS(Hadoop Distributed File System)', '리소스 관리자(resource mangaer)'인 'YARN(Yet Another Resource Negotiator)', 그리고 '분산 데이터 처리(distributed data processing)'의 기반인 'MapReduce' 3가지다. <br> 그 외의 프로젝트는 Hadoop 본체와는 독립적으로 개발되어 Hadoop을 이용한 분산 애플리케이션으로 동작한다.

모든 분산 시스템이 Hadoop에 의존하는 것이 아니라, Hadoop을 일부만 사용하거나 혹은 전혀 이용하지 않는 구성도 있다. <br> 예를 들어, 분산 파일 시스템으로는 'HDFS'를 사용하면서 리소스 관리자는 'Mesos', 분산 데이터 처리에는 'Spark'를 사용하는 구성도 가능하다. <br> 이처럼 다양한 소프트웨어 중에서 자신에게 맞는 것을 선택하고 그것들을 조합함으로써 시스템을 구성하는 것이 Hadoop을 중심으로 하는 데이터 처리의 특징이다.




**분산 파일 시스템과 리소스 관리자** (HDFS, YARN)

Hadoop에서 처리되는 데이터 대부분은 분산 파일 시스템인 HDFS에 저장된다. <br> 이것은 네트워크에 연결된 파일 서버와 같은 존재이지만, 다수의 컴퓨터에 파일을 복사하여 중복성을 높인다는 특징이 있다.

한편, CPU나 메모리 등의 계산 리소스는 리소스 매니저인 YARN에 의해 관리된다. <br> YARN은 애플리케이션이 사용하는 CPU 코어와 메모리를 '컨테이너(container)'라 불리는 단위로 관리한다. <br> Hadoop에서 분산 애플리케이션을 실행하면 YARN이 클러스터 전체의 부하를 보고 비어 있는 호스트부터 컨테이너를 할당한다.

분산 시스템은 많은 계산 리소스를 소비하지만, 호스트의 수에 따라 사용할 수 있는 리소스의 상한이 결정된다. <br> 한정된 리소스로 다수의 분산 애플리케이션이 동시에 실행되므로 애플리케이션 간에 리소스 쟁탈이 발생한다. <br> 리소스 관리자는 어느 애플리케이션에 얼마만큼의 리소스를 할당할 지 관리함으로써 모든 애플리케이션이 차질없이 실행되도록 제어한다.

리소스 관리자를 사용하면 애플리케이션마다 실행의 우선순위를 결정할 수 있다. <br> 그리하여 우선되는 작업부터 실행함으로써 한정된 리소스를 낭비 없이 활용하면서 데이터 처리를 진행하는 것이 가능하다.



**분산 데이터 처리 및 쿼리 엔진**



**Hive on Tez**



**대화형 쿼리 엔진**



### Spark - 인 메모리 형의 고속 데이터 처리


**MapReduce 대체하기**

