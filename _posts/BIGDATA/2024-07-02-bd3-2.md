---
title: "[BIGDATA] 3-2 쿼리 엔진"

categories: 
  - BIGDATA
tags:
  - [bigdata, 공부]

toc: true
toc_sticky: true
---

# 빅데이터의 분산 처리

## 쿼리 엔진

SQL-on-Hadoop에 의한 데이터 처리의 구체적인 예로서, 'Hive'에 의한 구조화 데이터의 생성과 'Presto'에 의한 대화식 쿼리에 대해 설명한다.


### 데이터 마트 구축의 파이프라인

Hadoop에 의한 구조화 데이터의 작성과 이를 이용한 쿼리의 실행이 어떤 것인지를 알기 위해, 하나의 예로서 Hive와 Presto를 결합한 데이터 파이프라인을 예상해보겠다.

우선 처음에 분산 스토리지에 저장된 데이터를 구조화하고 열 지향 스토리지 형식으로 저장한다. <br> 이것은 다수의 텍스트 파일을 읽어 들여 가공하는 부하가 큰 처리가 되기 때문에 Hive를 이용한다.

그리고 완성된 구조화 데이터를 결합, 집계하고 비정규화 테이블로 데이터 마트에 써서 내보낸다. <br> 열 지향 스토리지를 이용한 쿼리의 실행에는 Presto를 사용함으로써 실행 시간을 단축할 수 있다.

Hive에서 만든 각 테이블의 정보는 'Hive 메타 스토어(Hive Metastore)'라고 불리는 특별한 데이터베이스에 저장된다. <br> 이것은 Hive뿐만 아니라 다른 SQL-on-Hadoop의 쿼리 엔진에서도 공통의 테이블 정보로 참고된다.



### Hive에 의한 구조화 데이터 작성

우선 Hive를 사용하여 구조화 데이터를 작성한다. <br> 다음과 같이 단말 터미널에서 Hive를 시작하고 CREATE EXTERNAL TABLE로 '외부 테이블(external table)'을 정의한다.

```bat
$ Hive

CREATE EXTERNAL TABLE access_log_csv(
    time string, request string, status int, bytes int
)

ROW FORMAT SETDS 'org.apache.hadoop.hive.serde2.OpenCSVSerde'

STORED AS TEXTFILE LOCATION '/var/log/access_log/'

TBLPROPERTIES ('skip.header.line.count'='1');
```

```
OK
Time taken: 1.938 seconds
```

'외부 테이블'이란 Hive의 외부에 있는 특정 파일을 참고해 마치 거기에 테이블이 존재하는 것처럼 읽어 들이기 위해 지정한다. <br> 위의 예에서는 'access_log_csv'라는 테이블명을 참고해 데이터를 추출함으로써 텍스트 파일이 로드되고 구조화 데이터로의 변환이 이루어진다.

Hive를 비롯한 대부분의 SQL-on-Hadoop의 쿼리 엔진은 MPP 데이터베이스처럼 데이터를 내부로 가져오지 않아도 텍스트 파일을 그대로 집계할 수 있다. <br> 예를 들어, 다음과 같이 쿼리를 실행하면 외부 테이블로 지정한 경로에 포함된 모든 CSV 파일이 로드되고 집계된다.

```bat
SELECT status, count(*) cnt
FROM acess_log_csv GROUP BY status LIMIT 2;
```

```
OK
200    1701534
302    46573
Time taken: 8.664 seconds, Fetched: 2 row(s)
```

**열 지향 스토리지로의 변환**


**Hive로 비정규화 테이블을 작성하기**



**서브 쿼리 안에서 레코드 수 줄이기**


**데이터 편향 피하기**



### 대화형 쿼리 엔진 Presto의 구조 - Presto로 구조화 데이터 집계하기


**플러그인 가능한 스토리지**


**CPU 처리의 최적화**


**인 메모리 처리에  의한 고속화**


**분산 결합과 브로드캐스트 결합**


**열 지향 스토리지 집계**


### 데이터 분석의 프레임워크 선택하기 - MPP 데이터베이스, Hive, Presto, Spark


**MPP 데이터베이스**


**Hive**



**Presto**



**Spark**