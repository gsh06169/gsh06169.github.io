---
title: "[Python 머신러닝] 03-3 정밀도와 재현율"

categories: 
  - PYTHON
tags:
  - [Python, 프로그래밍, 머신러닝, 공부]

toc: true
toc_sticky: true
---

# 평가

## 정밀도와 재현율

- 정밀도 = $TP\over(FP + TP)$
    - 예측을 Positive로 한 대상 중에 예측과 실제값이 Positive로 일치한 데이터의 비율을 뜻한다.
- 재현율 = $TP\over(FN + TP)$
    - 실제값이 Positive인 대상 중에 예측과 실제값이 Positive로 일치한 데이터의 비율을 뜻한다.


#### 사이키럿의 정밀도, 재현율
- 정밀도는 precision_score(), 재현율은 recall_score() 제공


#### <실습> 
**MyFakeClassifier의 예측 결과로 정밀도와 재현율 측정**


```python
from sklearn.metrics import accuracy_score, precision_score , recall_score

print("정밀도:", precision_score(y_test, fakepred))
print("재현율:", recall_score(y_test, fakepred))
```

    정밀도: 0.0
    재현율: 0.0

-> 정확도의 문제점 인지


**오차행렬, 정확도, 정밀도, 재현율을 한꺼번에 계산하는 함수 생성**


```python
from sklearn.metrics import accuracy_score, precision_score , recall_score , confusion_matrix

def get_clf_eval(y_test , pred):
    confusion = confusion_matrix( y_test, pred)
    accuracy = accuracy_score(y_test , pred)
    precision = precision_score(y_test , pred)
    recall = recall_score(y_test , pred)
    print('오차 행렬')
    print(confusion)
    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}'.format(accuracy , precision ,recall))
```


```python
import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split 
from sklearn.linear_model import LogisticRegression
import warnings 
warnings.filterwarnings('ignore')

# 원본 데이터를 재로딩, 데이터 가공, 학습데이터/테스트 데이터 분할. 
titanic_df = pd.read_csv('./titanic_train.csv')
y_titanic_df = titanic_df['Survived']
X_titanic_df= titanic_df.drop('Survived', axis=1)
X_titanic_df = transform_features(X_titanic_df)

X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, \
                                                    test_size=0.20, random_state=11)

lr_clf = LogisticRegression(solver='liblinear')

lr_clf.fit(X_train , y_train)
pred = lr_clf.predict(X_test)
get_clf_eval(y_test , pred)
```

    오차 행렬
    [[108  10]
     [ 14  47]]
    정확도: 0.8659, 정밀도: 0.8246, 재현율: 0.7705


#### 업무에 따른 재현율과 정밀도의 상대적 중요도
- **재현율**이 상대적으로 더 중요한 지표인 경우는 실제 Positive 양성인 데이터 예측을 Negative 음성으로 잘못 판단하게 되면 업무상 큰 영향이 발생하는 경우이다. <br> 예) 암 진단, 금융사기 판별
- **정밀도**가 상대적으로 더 중요한 지표인 경우는 실제 Negative 음성인 데이터 예측을 Positive 양성으로 잘못 판단하게 되면 업무상 큰 영향을 발생하는 경우이다. <br> 예) 스팸 메일


### 정밀도/재현율 트레이드오프
- 분류하려는 업무의 특성상 정밀도 또는 재현울이 특별히 강조돼야 할 경우 분류의 결정 임계값(Threshold)을 조정해 정밀도 또는 재현율의 수치를 높일 수 있다.
- 하지만 정밀도와 재현율은 상호 보완적인 평가 지표이기 때문에 어느 한쪽을 강제로 높이면 다른 하나의 수치는 떨어지기 쉽다. <br> 이를 정밀도/재현율의 트레이드오프(Trade-off)라고 부른다.


#### 분류 결정 임곗값에 따른 Positive 예측 확률 변화
분류 결정 임곗값이 낮아질 수록 Positive로 예측할 확률이 높아진다. (재현율 증가)
- 사이킷런 Estimator 객체의 predict_proba() 메서드는 분류 결정 예측 확률을 반환한다.
- 이를 이용하면 임의로 분류 결정 임곗값을 조정하면서 예측 확률을 변경할 수 있다.


#### 분류 결정 임곗값에 따른 정밀도, 재현율 곡선
- 사이킷런은 precision_reacll_curve() 함수를 통해 임곗값에 따른 정밀도, 재현율의 변화값을 제공한다.


#### <실습> 
**predict_proba( ) 메소드 확인**

```python
pred_proba = lr_clf.predict_proba(X_test)
pred  = lr_clf.predict(X_test)
print('pred_proba()결과 Shape : {0}'.format(pred_proba.shape))
print('pred_proba array에서 앞 3개만 샘플로 추출 \n:', pred_proba[:3])

# 예측 확률 array 와 예측 결과값 array 를 concatenate 하여 예측 확률과 결과값을 한눈에 확인
pred_proba_result = np.concatenate([pred_proba , pred.reshape(-1,1)],axis=1)
print('두개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \n',pred_proba_result[:3])

```

    pred_proba()결과 Shape : (179, 2)
    pred_proba array에서 앞 3개만 샘플로 추출 
    : [[0.44935227 0.55064773]
     [0.86335512 0.13664488]
     [0.86429645 0.13570355]]
    두개의 class 중에서 더 큰 확률을 클래스 값으로 예측 
     [[0.44935227 0.55064773 1.        ]
     [0.86335512 0.13664488 0.        ]
     [0.86429645 0.13570355 0.        ]]

-> pred_proba array의 첫 번째 값: 0이 될 확률 <br> pred_proba array의 두 번째 값: 1이 될 확률 <br> 분류 결정값: 0.5 (1이 될 확률이 0.5보다 크면 1 반환, 작으면 0 반환)

**Binarizer 활용**


```python
from sklearn.preprocessing import Binarizer

X = [[ 1, -1,  2],
     [ 2,  0,  0],
     [ 0,  1.1, 1.2]]

# threshold 기준값보다 같거나 작으면 0을, 크면 1을 반환
binarizer = Binarizer(threshold=1.1)                     
print(binarizer.fit_transform(X))
```

    [[0. 0. 1.]
     [1. 0. 0.]
     [0. 0. 1.]]
    

**분류 결정 임계값 0.5 기반에서 Binarizer를 이용하여 예측값 변환**


```python
from sklearn.preprocessing import Binarizer

#Binarizer의 threshold 설정값. 분류 결정 임곗값임.  
custom_threshold = 0.5

# predict_proba( ) 반환값의 두번째 컬럼 , 즉 Positive 클래스 컬럼 하나만 추출하여 Binarizer를 적용
pred_proba_1 = pred_proba[:,1].reshape(-1,1)

binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1) 
custom_predict = binarizer.transform(pred_proba_1)

get_clf_eval(y_test, custom_predict)
```

    오차 행렬
    [[108  10]
     [ 14  47]]
    정확도: 0.8659, 정밀도: 0.8246, 재현율: 0.7705
    

**분류 결정 임계값 0.4 기반에서 Binarizer를 이용하여 예측값 변환**


```python
# Binarizer의 threshold 설정값을 0.4로 설정. 즉 분류 결정 임곗값을 0.5에서 0.4로 낮춤  
custom_threshold = 0.4
pred_proba_1 = pred_proba[:,1].reshape(-1,1)
binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1) 
custom_predict = binarizer.transform(pred_proba_1)

get_clf_eval(y_test , custom_predict)
```

    오차 행렬
    [[97 21]
     [11 50]]
    정확도: 0.8212, 정밀도: 0.7042, 재현율: 0.8197
    

**여러개의 분류 결정 임곗값을 변경하면서  Binarizer를 이용하여 예측값 변환**


```python
# 테스트를 수행할 모든 임곗값을 리스트 객체로 저장. 
thresholds = [0.4, 0.45, 0.50, 0.55, 0.60]

def get_eval_by_threshold(y_test , pred_proba_c1, thresholds):
    # thresholds list객체내의 값을 차례로 iteration하면서 Evaluation 수행.
    for custom_threshold in thresholds:
        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1) 
        custom_predict = binarizer.transform(pred_proba_c1)
        print('임곗값:',custom_threshold)
        get_clf_eval(y_test , custom_predict)

get_eval_by_threshold(y_test ,pred_proba[:,1].reshape(-1,1), thresholds )
```

    임곗값: 0.4
    오차 행렬
    [[97 21]
     [11 50]]
    정확도: 0.8212, 정밀도: 0.7042, 재현율: 0.8197
    임곗값: 0.45
    오차 행렬
    [[105  13]
     [ 13  48]]
    정확도: 0.8547, 정밀도: 0.7869, 재현율: 0.7869
    임곗값: 0.5
    오차 행렬
    [[108  10]
     [ 14  47]]
    정확도: 0.8659, 정밀도: 0.8246, 재현율: 0.7705
    임곗값: 0.55
    오차 행렬
    [[111   7]
     [ 16  45]]
    정확도: 0.8715, 정밀도: 0.8654, 재현율: 0.7377
    임곗값: 0.6
    오차 행렬
    [[113   5]
     [ 17  44]]
    정확도: 0.8771, 정밀도: 0.8980, 재현율: 0.7213
    

** precision_recall_curve( ) 를 이용하여 임곗값에 따른 정밀도-재현율 값 추출 **


```python
from sklearn.metrics import precision_recall_curve

# 레이블 값이 1일때의 예측 확률을 추출 
pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1] 

# 실제값 데이터 셋과 레이블 값이 1일 때의 예측 확률을 precision_recall_curve 인자로 입력 
precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_class1 )
print('반환된 분류 결정 임곗값 배열의 Shape:', thresholds.shape)
print('반환된 precisions 배열의 Shape:', precisions.shape)
print('반환된 recalls 배열의 Shape:', recalls.shape)

print('thresholds 5 sample:', thresholds[:5])
print('precisions 5 sample:', precisions[:5])
print('recalls 5 sample:', recalls[:5])

#반환된 임계값 배열 로우가 147건이므로 샘플로 10건만 추출하되, 임곗값을 15 Step으로 추출. 
thr_index = np.arange(0, thresholds.shape[0], 15)
print('샘플 추출을 위한 임계값 배열의 index 10개:', thr_index)
print('샘플용 10개의 임곗값: ', np.round(thresholds[thr_index], 2))

# 15 step 단위로 추출된 임계값에 따른 정밀도와 재현율 값 
print('샘플 임계값별 정밀도: ', np.round(precisions[thr_index], 3))
print('샘플 임계값별 재현율: ', np.round(recalls[thr_index], 3))
```

    반환된 분류 결정 임곗값 배열의 Shape: (147,)
    반환된 precisions 배열의 Shape: (148,)
    반환된 recalls 배열의 Shape: (148,)
    thresholds 5 sample: [0.11573101 0.11636721 0.11819211 0.12102773 0.12349478]
    precisions 5 sample: [0.37888199 0.375      0.37735849 0.37974684 0.38216561]
    recalls 5 sample: [1.         0.98360656 0.98360656 0.98360656 0.98360656]
    샘플 추출을 위한 임계값 배열의 index 10개: [  0  15  30  45  60  75  90 105 120 135]
    샘플용 10개의 임곗값:  [0.12 0.13 0.15 0.17 0.26 0.38 0.49 0.63 0.76 0.9 ]
    샘플 임계값별 정밀도:  [0.379 0.424 0.455 0.519 0.618 0.676 0.797 0.93  0.964 1.   ]
    샘플 임계값별 재현율:  [1.    0.967 0.902 0.902 0.902 0.82  0.77  0.656 0.443 0.213]
    

**임곗값의 변경에 따른 정밀도-재현율 변화 곡선을 그림**


```python
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
%matplotlib inline

def precision_recall_curve_plot(y_test , pred_proba_c1):
    # threshold ndarray와 이 threshold에 따른 정밀도, 재현율 ndarray 추출. 
    precisions, recalls, thresholds = precision_recall_curve( y_test, pred_proba_c1)
    
    # X축을 threshold값으로, Y축은 정밀도, 재현율 값으로 각각 Plot 수행. 정밀도는 점선으로 표시
    plt.figure(figsize=(8,6))
    threshold_boundary = thresholds.shape[0]
    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision')
    plt.plot(thresholds, recalls[0:threshold_boundary],label='recall')
    
    # threshold 값 X 축의 Scale을 0.1 단위로 변경
    start, end = plt.xlim()
    plt.xticks(np.round(np.arange(start, end, 0.1),2))
    
    # x축, y축 label과 legend, 그리고 grid 설정
    plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')
    plt.legend(); plt.grid()
    plt.show()
    
precision_recall_curve_plot( y_test, lr_clf.predict_proba(X_test)[:, 1] )

```


    
![output_31_0](https://github.com/gsh06169/gsh06169/assets/150469460/2eb6b1e1-a3b2-44f7-a796-77691d4baeb0)


### 정밀도와 재현율의 맹점
- 정밀도를 100%로 만드는 법
    - 확실한 기준이 되는 경우만 Positive로 예측하고 나머지는 모두 Negative로 예측한다. <br> 전체 환자 1000명 중 확실한 Positive 징후만 가진 환자는 단 1명이라고 하면 이 한 명만 Positive로 예측하고 나머지는 모두 Negative로 예측하더라고 FP는 0, TP는 1이므로 정밀도는 1/(1+0)으로 100%가 된다.
- 재현율을 100%로 만드는 법  
    - 모든 환자를 Positive로 예측하면 된다. <br> 전체 환자 1000명을 다 Positive로 예측하면 이 중 실제 양성인 사람이 30명 정도라도 TN이 수치에 포함되지 않고 FN은 아예 0이므로 30/(30+0)으로 100%가 된다.