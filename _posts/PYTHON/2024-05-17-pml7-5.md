---
title: "[Python 머신러닝] 07-5 DBSCAN"

categories: 
  - PYTHON
tags:
  - [Python, 프로그래밍, 머신러닝, 공부]

toc: true
toc_sticky: true
---

# 군집화


## DBSCAN


### DBSCAN 개요

#### DBSCAN(Density Based Spatial Clustering of Applications with Noise)

DBSCAN은 특정 공간 내에 데이터 밀도 차이를 기반 알고리즘으로 하고 있어서 복잡한 기하학적 분포도를 가진 데이터 세트에 대해서도 군집화를 잘 수행한다.


DBSCAN은 알고리즘이 데이터 밀도 차이를 자동으로 감지하여 군집을 생성하므로 사용자가 군집 개수를 지정할 수 없다.


#### 군집화 알고리즘별 비교

![스크린샷 2024-05-16 180006](https://github.com/gsh06169/gsh06169/assets/150469460/0bbb24e8-c4ad-4a8f-93d9-b89e5d12b2de)

- DBSCAN은 데이터의 밀도가 자주 변하거나, 아예 모든 데이터의 밀도가 크게 변하지 않으면 군집화 성능이 떨어진다.

- 피처의 개수가 많으면 군집화 성능이 떨어진다.


#### DBSCAN 구성 요소

![스크린샷 2024-05-16 180257](https://github.com/gsh06169/gsh06169/assets/150469460/f17fe1ba-e305-4c89-ab23-a0b7268af710)

DBSCAN을 구성하는 가장 중요한 두 가지 파라미터는 입실론(epsilon)으로 표기하는 주변 영역과 이 입실론 주변 영역에 포함되는 최소 데이터의 개수 min points이다.

- 입실론 주변 영역 (epsilon): 개별 데이터를 중심으로 입실론 반경을 가지는 원형의 영역
- 최소 데이터 개수 (min points): 개별 데이터의 입실론 주변 영역에 포함되는 타 데이터의 개수



입실론 주변 영역 내에 포함되는 최소 데이터 개수를 충족시키는가 아닌가에 따라 데이터 포인트를 다음과 같이 정의한다.

- 핵심 포인트(Core Point): 주변 영역 내에 최소 데이터 개수 이상의 타 데이터를 가지고 있을 경우 해당 데이터를 핵심 포인트라고 한다.
- 이웃 포인트(Neighbor Point): 주변 영역 내에 위치한 타 데이터를 이웃 포인트라고 한다.
- 경계 포인트(Border Point): 주변 영역 내에 최소 데이터 개수 이상의 이웃 포인트를 가지고 있지 않지만 핵심 포인트를 이웃 포인트로 가지고 있는 데이터를 경계 포인트라고 한다.
- 잡음 포인트(Noise Point): 최소 데이터 개수 이상의 이웃 포인트를 가지고 있지 않으며, 핵심 포인트도 이웃 포인트로 가지고 있지 않는 데이터를 잡음 포인트라고 한다.



#### DBSCAN 절차


![스크린샷 2024-05-16 213954](https://github.com/gsh06169/gsh06169/assets/150469460/df7664bc-6f0d-4747-a798-706df93170e5)

1. P1에서 P12까지 12개의 데이터 세트에 대해서 DBSCAN 군집화를 적용하면서 주요 개념을 설명 <br> 특정 입실론 반경 내에 포함될 최소 데이터 세트를 6개로(자기 자신의 데이터 포함) 가정

2. P1 데이터를 기준으로 입실론 반경 내에 포함된 데이터가 7개(자신은 P1, 이웃 데이터: P2, P6, P7, P8, P9, P11)로 최소 데이터 5개 이상을 만족하므로 P1 데이터는 핵심 포인트(Core Point)

3. 다음으로 P2 데이터 역시 반경 내에 6개의 데이터(자신은 P2, 이웃 데이터: P1, P3, P4, P9, P10)를 가지고 있으므로 핵심 포인트

4. 핵심 포인트 P1의 이웃 데이터 포인트 P2 역시 핵심 포인트일 경우 P1에서 P2로 연결해 직접 접근이 가능

5. 특정 핵심 포인트에서 직접 접근이 가능한 다른 핵심 포인트를 서로 연결하면서 군집화를 구성 <br> 이러한 방식으로 점차적으로 군집(Cluster) 영역을 확장해 나가는 것이 DBSCAN 군집화 방식

6. P3 데이터의 경우 반경 내에 포함되는 이웃 데이터는 P2, P4로 2개이므로 군집으로 구분할 수 있는 핵심 포인트가 될 수 없음 <br> 하지만 이웃 데이터 중에 핵심 포인트 P2를 가지고 있음 <br> 이처럼 자신은 핵심 포인트가 아니지만, 이웃 데이터로 핵심 포인트를 가지고 있는 데이터를 경계 포인트(Border Point)라고 함 <br> 경계 포인트는 군집의 외곽을 형성

7. 그림의 P5와 같이 반경 내에 최소 데이터를 가지고 있지도 않고 핵심 포인트 또한 이웃 데이터로 가지고 있지 않는 데이터를 잡읍 포인트(Noise Point)라고 함


#### 사이킷런 DBSCAN

사이킷런은 DBSCAN 클래스를 통해 DBSCAN 알고리즘을 지원한다. <br> DBSCAN 클래스는 다음과 같은 주요한 초기화 파라미터를 가지고 있다.

- eps: 입실론 주면 영역의 반경을 의미
- min_smaples: 핵심 포인트가 되기 위해 입실론 주변 영역 내에 포함돼야 할 데이터의 최소 개수를 의미 (자신의 데이터를 포함)


### DBSCAN 적용하기 - 붓꽃 데이터 세트

#### <실습>

```python
from sklearn.datasets import load_iris

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
%matplotlib inline

iris = load_iris()
feature_names = ['sepal_length','sepal_width','petal_length','petal_width']

# 보다 편리한 데이타 Handling을 위해 DataFrame으로 변환
irisDF = pd.DataFrame(data=iris.data, columns=feature_names)
irisDF['target'] = iris.target
irisDF.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sepal_length</th>
      <th>sepal_width</th>
      <th>petal_length</th>
      <th>petal_width</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.1</td>
      <td>3.5</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.9</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.7</td>
      <td>3.2</td>
      <td>1.3</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.6</td>
      <td>3.1</td>
      <td>1.5</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>3.6</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>



**eps 0.6 min_samples=8 로 DBSCAN 군집화 적용**


```python
from sklearn.cluster import DBSCAN

dbscan = DBSCAN(eps=0.6, min_samples=8, metric='euclidean')
dbscan_labels = dbscan.fit_predict(iris.data)

irisDF['dbscan_cluster'] = dbscan_labels

iris_result = irisDF.groupby(['target'])['dbscan_cluster'].value_counts()
print(iris_result)
```

    target  dbscan_cluster
    0        0                49
            -1                 1
    1        1                46
            -1                 4
    2        1                42
            -1                 8
    Name: dbscan_cluster, dtype: int64
    


```python
### 클러스터 결과를 담은 DataFrame과 사이킷런의 Cluster 객체등을 인자로 받아 클러스터링 결과를 시각화하는 함수  
def visualize_cluster_plot(clusterobj, dataframe, label_name, iscenter=True):
    if iscenter :
        centers = clusterobj.cluster_centers_
        
    unique_labels = np.unique(dataframe[label_name].values)
    markers=['o', 's', '^', 'x', '*']
    isNoise=False

    for label in unique_labels:
        label_cluster = dataframe[dataframe[label_name]==label]
        if label == -1:
            cluster_legend = 'Noise'
            isNoise=True
        else :
            cluster_legend = 'Cluster '+str(label)
        
        plt.scatter(x=label_cluster['ftr1'], y=label_cluster['ftr2'], s=70,\
                    edgecolor='k', marker=markers[label], label=cluster_legend)
        
        if iscenter:
            center_x_y = centers[label]
            plt.scatter(x=center_x_y[0], y=center_x_y[1], s=250, color='white',
                        alpha=0.9, edgecolor='k', marker=markers[label])
            plt.scatter(x=center_x_y[0], y=center_x_y[1], s=70, color='k',\
                        edgecolor='k', marker='$%d$' % label)
    if isNoise:
        legend_loc='upper center'
    else: legend_loc='upper right'
    
    plt.legend(loc=legend_loc)
    plt.show()
```

**PCA 2개 컴포넌트로 기존 feature들을 차원 축소 후 시각화**


```python
from sklearn.decomposition import PCA
# 2차원으로 시각화하기 위해 PCA n_componets=2로 피처 데이터 세트 변환
pca = PCA(n_components=2, random_state=0)
pca_transformed = pca.fit_transform(iris.data)
# visualize_cluster_2d( ) 함수는 ftr1, ftr2 컬럼을 좌표에 표현하므로 PCA 변환값을 해당 컬럼으로 생성
irisDF['ftr1'] = pca_transformed[:,0]
irisDF['ftr2'] = pca_transformed[:,1]

visualize_cluster_plot(dbscan, irisDF, 'dbscan_cluster', iscenter=False)
```


![output_6_0](https://github.com/gsh06169/gsh06169/assets/150469460/93046c00-ecfc-4788-8855-3faac7cbd70b)
    


**eps의 크기를 증가 한 후 노이즈 확인**


```python
from sklearn.cluster import DBSCAN

dbscan = DBSCAN(eps=0.8, min_samples=8, metric='euclidean')
dbscan_labels = dbscan.fit_predict(iris.data)

irisDF['dbscan_cluster'] = dbscan_labels
irisDF['target'] = iris.target

iris_result = irisDF.groupby(['target'])['dbscan_cluster'].value_counts()
print(iris_result)

visualize_cluster_plot(dbscan, irisDF, 'dbscan_cluster', iscenter=False)

```

    target  dbscan_cluster
    0        0                50
    1        1                50
    2        1                47
            -1                 3
    Name: dbscan_cluster, dtype: int64
    


    
![output_8_1](https://github.com/gsh06169/gsh06169/assets/150469460/21dcc23d-5af9-4c6d-ae9a-774a37b24e18)
    


**min_samples의 크기를 증가 후 노이즈 확인**


```python
dbscan = DBSCAN(eps=0.6, min_samples=16, metric='euclidean')
dbscan_labels = dbscan.fit_predict(iris.data)

irisDF['dbscan_cluster'] = dbscan_labels
irisDF['target'] = iris.target

iris_result = irisDF.groupby(['target'])['dbscan_cluster'].value_counts()
print(iris_result)
visualize_cluster_plot(dbscan, irisDF, 'dbscan_cluster', iscenter=False)
```

    target  dbscan_cluster
    0        0                48
            -1                 2
    1        1                44
            -1                 6
    2        1                36
            -1                14
    Name: dbscan_cluster, dtype: int64
    


    
![output_10_17](https://github.com/gsh06169/gsh06169/assets/150469460/24e454c3-4419-4938-8a54-c5b20c7d8c74)
    


### DBSCAN 적용하기 - make_circles( ) 데이터 세트

#### <실습>


```python
from sklearn.datasets import make_circles

X, y = make_circles(n_samples=1000, shuffle=True, noise=0.05, random_state=0, factor=0.5)
clusterDF = pd.DataFrame(data=X, columns=['ftr1', 'ftr2'])
clusterDF['target'] = y

visualize_cluster_plot(None, clusterDF, 'target', iscenter=False)

```


    
![output_12_075](https://github.com/gsh06169/gsh06169/assets/150469460/43d27cab-f4a5-44cb-b858-1dcceead8de2)
    



```python
# KMeans로 make_circles( ) 데이터 셋을 클러스터링 수행. 
from sklearn.cluster import KMeans

kmeans = KMeans(n_clusters=2, max_iter=1000, random_state=0)
kmeans_labels = kmeans.fit_predict(X)
clusterDF['kmeans_cluster'] = kmeans_labels

visualize_cluster_plot(kmeans, clusterDF, 'kmeans_cluster', iscenter=True)

```


    
![output_13_0](https://github.com/gsh06169/gsh06169/assets/150469460/cf3819aa-69e1-4eb8-877b-e173ad57626e)

    



```python
# GMM으로 make_circles( ) 데이터 셋을 클러스터링 수행. 
from sklearn.mixture import GaussianMixture

gmm = GaussianMixture(n_components=2, random_state=0)
gmm_label = gmm.fit(X).predict(X)
clusterDF['gmm_cluster'] = gmm_label

visualize_cluster_plot(gmm, clusterDF, 'gmm_cluster', iscenter=False)

```


    

![output_14_075](https://github.com/gsh06169/gsh06169/assets/150469460/3483992d-2d3b-44f3-9dc1-97731da7c60f)
    



```python
# DBSCAN으로 make_circles( ) 데이터 셋을 클러스터링 수행. 
from sklearn.cluster import DBSCAN

dbscan = DBSCAN(eps=0.2, min_samples=10, metric='euclidean')
dbscan_labels = dbscan.fit_predict(X)
clusterDF['dbscan_cluster'] = dbscan_labels

visualize_cluster_plot(dbscan, clusterDF, 'dbscan_cluster', iscenter=False)

```


    
![output_15_0](https://github.com/gsh06169/gsh06169/assets/150469460/f5329db0-fc9d-4ef2-978e-4eb0ee5a4d0f)
    


