---
title: "[Python 머신러닝] 05-2 단순 선형 회귀를 통한 회귀 이해"

categories: 
  - PYTHON
tags:
  - [Python, 프로그래밍, 머신러닝, 공부]

toc: true
toc_sticky: true
---

# 회귀

## 단순 선형 회귀를 통한 회귀 이해

주택 가격이 주택의 크기로만 결정되는 단순 선형 회귀로 가정하면 다음과 같이 주택 가격은 주택 크기에 대해 선형(직선 형태)의 관계로 표현할 수 있다.
![IMG_2577](https://github.com/gsh06169/gsh06169/assets/150469460/7f45ff9b-90a0-4c81-94e2-f7680be7b54f)
-> 최적의 회귀 모델을 만든다는 것은 바로 전체 데이터의 잔차(오류 값) 합이 최소가 되는 모델을 만든다는 의미이다. <br> 동시에 오류 값 합이 최소가 될 수 있는 최적의 회귀 계수를 찾는 다는 의미도 된다.


### RSS 기반의 회귀 오류 측정

RSS: 오류 값의 제곱을 구해서 더하는 방식 <br> 일반적으로 미분 등의 계산을 편리하게 하기 위해서 RSS 방식으로 오류 합을 구한다. (즉, $Error^2$ = RSS)

RSS = (#1 주택 가격 - ($w0$ + $w1$ $\times$ #1 주택 크기))$^2$ + (#2 주택 가격 - ($w0$ + $w1$ $\times$ #2 주택 크기))$^2$ + (#3 주택 가격 - ($w0$ + $w1$ $\times$ #3 주택 크기))$^2$ + ... (모든 학습 데이터에 대해 RSS 수행)


### RSS의 이해

- RSS는 이제 변수가 $W_0, W_1$인 식으로 표현할 수 있으며, 이 RSS를 최소로 하는 $W_0, W_1$, 즉 회귀 계수를 학습을 통해서 찾는 것이 머신러닝 기반 회귀의 핵심 사항이다.
- RSS는 회귀식의 독립변수 X, 종속변수 Y가 중심 변수가 아니라 w 변수(회귀 계수)가 중심 변수임을 인지하는 것이 매우 중요하다. (학습 데이터로 입력되는 독립변수와 종속변수는 RSS에서 모두 상수로 간주한다.)
- 일반적으로 RSS는 학습 데이터의 건수로 나누어서 다음과 같이 정규화된 식으로 표현된다.  
    $RSS(w_0, w_1)$ = $1 \over N$ $\sum_{i=1}^{N}{(y_i - (w_0 + w_1 \times x_i))^2}$  
    ($i$는 1부터 학습 데이터의 총 건수 $N$까지)


### RSS - 회귀의 비용 함수
회귀에서 RSS는 비용(Cost)이며 w 변수(회귀 계수)로 구성되는 RSS를 비용 함수라고 한다. <br> 머신러닝 회귀 알고리즘은 데이터를 계속 학습하면서 이 비용 함수가 반환하는 값(즉, 오류 값)을 지속해서 감소시키고 최종적으로 더 이상 감소하지 않는 최소의 오류 값을 구하는 것이다. <br> 비용 함수를 손실 함수(loss function)라고도 한다.


