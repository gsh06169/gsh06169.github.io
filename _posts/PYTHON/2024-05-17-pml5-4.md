---
title: "[Python 머신러닝] 05-4 사이킷런 LinearRegression을 이용한 보스턴 주택 가격 예측"

categories: 
  - PYTHON
tags:
  - [Python, 프로그래밍, 머신러닝, 공부]

toc: true
toc_sticky: true
---

# 회귀


## 사이킷런 LinearRegression을 이용한 보스턴 주택 가격 예측


### LinearRegression 클래스 - Ordinary Least Squares

```
class sklearn.linear_model.LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=1)
```
- linearRegression 클래스는 예측값과 실제 값의 RSS(Residual Sum of Squares)를 최소화하는 OLS(Ordinary Least Squares) 추정 방식으로 구현한 클래스이다. 
- LinearRegression 클래스는 fit( ) 메서드로 X, y 배열을 입력받으면 회귀 계수(Coefficients)인 W를 coef_ 속성에 저장한다.

입력 파라미터|fit_intercept: 불린 값으로, 디폴트는 True이다. <br> intercept(절편) 값을 계산할 것인지 말지를 지정한다. <br> 만일 False로 지정하면 intercept가 사용되지 않고 0으로 지정된다. <br> normalize: 불린 값으로 디폴트는 False이다. <br> fit_intercept가 False인 경우에는 이 파라미터가 무시된다. <br> 만일 True이면 회귀를 수행하기 전에 입력 데이터 세트를 정규화한다.
---|---
**속성**|**coef_: fit( ) 메서드를 수행했을 때 회귀 계수가 배열 형태로 저장하는 속성 <br> Shape는 (Target값 개수, 피처 개수) <br> intercept_: intercept 값**


#### 선형 회귀의 다중 공선성 문제

일반적으로 선형 회귀는 입력 피처의 독립성에 많은 영향을 받는다. <br> 피처 간의 상관관계가 매우 높은 경우 분산이 매우 커져서 오류에 매우 민감해진다. <br> 이러한 현상을 다중 공선성(multi-collinearity) 문제라고 한다. <br> 일반적으로 상관관계가 높은 피처가 많은 경우 독립적인 중요한 피처만 남기고 제거하거나 규제를 적용한다.

### 회귀 평가 지표

평가 지표|설명|수식
---|---|---
MAE|Mean Absolute Error(MAE)이며 실제 값과 예측값의 차이를 절댓값으로 변환해 평균한 것|${1 \over n}$ $\sum_{i=1}^{n}{\vert{Y_i  - \hat{Y}_i}\vert}$
MSE|Mean Squared Error(MSE)이며 실제 값과 예측값의 차이를 제곱해 평균한 것|${1 \over n}$ $\sum_{i=1}^{n}{(Y_i  - \hat{Y}_i)^2}$
MSLE|MSE에 로그를 적용한 것 <br> 결정값이 클수록 오류값도 커지기 때문에 일부 큰 오류값들로 인해 전체 오류값이 커지는 것을 막아준다.|${1 \over n}$ $\sum_{i=1}^{n}{(log(Y_i + 1) - log(\hat{Y}_i + 1))^2}$
RMSE|MSE 값은 오류의 제곱을 구하므로 실제 오류 평균보다 더 커지는 특성이 있으므로 MSE에 로트를 씌운 것|$\sqrt{1 \over n}$ $\sum_{i=1}^{n}{(Y_i  - \hat{Y}_i)^2}$
RMSLE|RMSE에 로그를 적용한 것 <br> 결정값이 클수록 오류값도 커지기 때문에 일부 큰 오류값들로 인해 전체 오류값이 커지는 것을 막아준다.|$\sqrt{1 \over n}$ $\sum_{i=1}^{n}{(log(Y_i + 1) - log(\hat{Y}_i + 1))^2}$
$R^2$|분산 기반으로 예측 성능을 평가한다. <br> 실제 값의 분산 대비 예측값의 분산 비율을 지표로 하며, 1에 가까울수록 예측 정확도가 높다.|$예측값 Variance \over 실제 값 Variance$

