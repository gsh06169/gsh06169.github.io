---
title: "[Python 머신러닝] 05-4 사이킷런 LinearRegression을 이용한 보스턴 주택 가격 예측"

categories: 
  - PYTHON
tags:
  - [Python, 프로그래밍, 머신러닝, 공부]

toc: true
toc_sticky: true
---

# 회귀


## 사이킷런 LinearRegression을 이용한 보스턴 주택 가격 예측


### LinearRegression 클래스 - Ordinary Least Squares

```
class sklearn.linear_model.LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=1)
```
- linearRegression 클래스는 예측값과 실제 값의 RSS(Residual Sum of Squares)를 최소화하는 OLS(Ordinary Least Squares) 추정 방식으로 구현한 클래스이다. 
- LinearRegression 클래스는 fit( ) 메서드로 X, y 배열을 입력받으면 회귀 계수(Coefficients)인 W를 coef_ 속성에 저장한다.

입력 파라미터|fit_intercept: 불린 값으로, 디폴트는 True이다. <br> intercept(절편) 값을 계산할 것인지 말지를 지정한다. <br> 만일 False로 지정하면 intercept가 사용되지 않고 0으로 지정된다. <br> normalize: 불린 값으로 디폴트는 False이다. <br> fit_intercept가 False인 경우에는 이 파라미터가 무시된다. <br> 만일 True이면 회귀를 수행하기 전에 입력 데이터 세트를 정규화한다.
---|---
**속성**|**coef_: fit( ) 메서드를 수행했을 때 회귀 계수가 배열 형태로 저장하는 속성 <br> Shape는 (Target값 개수, 피처 개수) <br> intercept_: intercept 값**


#### 선형 회귀의 다중 공선성 문제

일반적으로 선형 회귀는 입력 피처의 독립성에 많은 영향을 받는다. <br> 피처 간의 상관관계가 매우 높은 경우 분산이 매우 커져서 오류에 매우 민감해진다. <br> 이러한 현상을 다중 공선성(multi-collinearity) 문제라고 한다. <br> 일반적으로 상관관계가 높은 피처가 많은 경우 독립적인 중요한 피처만 남기고 제거하거나 규제를 적용한다.

### 회귀 평가 지표

평가 지표|설명|수식
---|---|---
MAE|Mean Absolute Error(MAE)이며 실제 값과 예측값의 차이를 절댓값으로 변환해 평균한 것|${1 \over n}$ $\sum_{i=1}^{n}{\vert{Y_i  - \hat{Y}_i}\vert}$
MSE|Mean Squared Error(MSE)이며 실제 값과 예측값의 차이를 제곱해 평균한 것|${1 \over n}$ $\sum_{i=1}^{n}{(Y_i  - \hat{Y}_i)^2}$
MSLE|MSE에 로그를 적용한 것 <br> 결정값이 클수록 오류값도 커지기 때문에 일부 큰 오류값들로 인해 전체 오류값이 커지는 것을 막아준다.|${1 \over n}$ $\sum_{i=1}^{n}{(log(Y_i + 1) - log(\hat{Y}_i + 1))^2}$
RMSE|MSE 값은 오류의 제곱을 구하므로 실제 오류 평균보다 더 커지는 특성이 있으므로 MSE에 로트를 씌운 것|$\sqrt{1 \over n}$ $\sum_{i=1}^{n}{(Y_i  - \hat{Y}_i)^2}$
RMSLE|RMSE에 로그를 적용한 것 <br> 결정값이 클수록 오류값도 커지기 때문에 일부 큰 오류값들로 인해 전체 오류값이 커지는 것을 막아준다.|$\sqrt{1 \over n}$ $\sum_{i=1}^{n}{(log(Y_i + 1) - log(\hat{Y}_i + 1))^2}$
$R^2$|분산 기반으로 예측 성능을 평가한다. <br> 실제 값의 분산 대비 예측값의 분산 비율을 지표로 하며, 1에 가까울수록 예측 정확도가 높다.|$예측값 Variance \over 실제 값 Variance$

#### MAE와 RMSE의 비교

MAE에 비해 RMSE는 큰 오류값에 상대적인 페널티를 더 부여한다. <br> 예를 들어, 다섯 개의 오류값(실제 값과 예측값의 차이)이 10, 20, 10, 10, 100과 같이 다른 값에 비해 큰 오류값이 존재하는 경우 RMSE는 전반적으로 MAE보다 높다. (MAE = 30, RMSE = 46.26)


#### 사이킷런 회귀 평가 API

평가 방법|사이킷런 평가 지표 API|Scoring 함수 적용 값
---|---|---
MAE| metrics.mean_absolute_error|'neg_mean_absolute_error'
MSE|metrics.mean_squared_error|'neg_mean_squared_error'
RMSE|metrics.mean_squared_error를 그대로 사용하되 squared 파라미터를 False로 설정|'neg_root_mean_squared_error'
MSLE|matrics.mean_squared_log_error|'neg_mean_squared_log_error'
$R^2$|metrics.r2_score|'r2'

##### 사이킷런 Scoring 함수에 회귀 평가 적용 시 유의사항

cross_val_score, GridSearchCV와 같은 Scoring 함수에 회귀 평가 지표를 적용 시 유의사항
- MAE의 사이킷런 scoring 파라미터 값은 'neg_mean_absolute_error'이다. <br> 이는 Negative(음수) 값을 가진다는 의미인데, MAE는 절댓값의 합이기 때문에 음수가 될 수 없다.
- Scoring 함수에 'neg_mean_absolute_error'를 적용해 음수값을 반환하는 이유는 사이킷런의 Scoring 함수가 score 값이 클수록 좋은 평가 결과로 자동 평가하기 때문이다. <br> 따라서 -1을 원래의 평가 지표 값에 곱해서 음수를 만들어 작은 오류 값이 더 큰 숫자로 인식하게 한다.
- metrics.mean_absolute_error( )와 같은 사이킷런 평가 지표 API는 정상적으로 양수의 값을 반환한다. <br> 하지만 Scoring 함수의 scoring 파라미터 값 'neg_mean_absolute_error'가 의미하는 것은 -1*metrics.mean_absolute_error( )이니 주의가 필요하다.




### LinearRegression을 이용해 보스턴 주택 가격 회귀 구현


#### <실습>